{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"AmpiricDataset/V4/final.csv\")\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Split dataset into features and labels\n",
    "X = df.drop(columns=['Label'])\n",
    "y = df['Label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Logistic Regression ----\n",
      "Accuracy: 0.9691\n",
      "F1: 0.9691\n",
      "Precision: 0.9691\n",
      "Recall: 0.9691\n",
      "ROC AUC: 0.9932\n",
      "\n",
      "Cross-validation Results:\n",
      "accuracy: 0.9690 ± 0.0017\n",
      "f1: 0.9690 ± 0.0017\n",
      "precision: 0.9690 ± 0.0017\n",
      "recall: 0.9690 ± 0.0017\n",
      "roc_auc: 0.9924 ± 0.0006\n",
      "\n",
      "---- SVM ----\n",
      "Accuracy: 0.9772\n",
      "F1: 0.9772\n",
      "Precision: 0.9775\n",
      "Recall: 0.9772\n",
      "ROC AUC: 0.9958\n",
      "\n",
      "Cross-validation Results:\n",
      "accuracy: 0.9775 ± 0.0012\n",
      "f1: 0.9775 ± 0.0012\n",
      "precision: 0.9778 ± 0.0012\n",
      "recall: 0.9775 ± 0.0012\n",
      "roc_auc: 0.9952 ± 0.0003\n",
      "\n",
      "---- KNN ----\n",
      "Accuracy: 0.9967\n",
      "F1: 0.9967\n",
      "Precision: 0.9967\n",
      "Recall: 0.9967\n",
      "ROC AUC: 0.9996\n",
      "\n",
      "Cross-validation Results:\n",
      "accuracy: 0.9963 ± 0.0002\n",
      "f1: 0.9963 ± 0.0002\n",
      "precision: 0.9963 ± 0.0002\n",
      "recall: 0.9963 ± 0.0002\n",
      "roc_auc: 0.9993 ± 0.0004\n",
      "\n",
      "---- Random Forest ----\n",
      "Accuracy: 0.9964\n",
      "F1: 0.9964\n",
      "Precision: 0.9964\n",
      "Recall: 0.9964\n",
      "ROC AUC: 0.9998\n",
      "\n",
      "Cross-validation Results:\n",
      "accuracy: 0.9953 ± 0.0008\n",
      "f1: 0.9953 ± 0.0008\n",
      "precision: 0.9953 ± 0.0008\n",
      "recall: 0.9953 ± 0.0008\n",
      "roc_auc: 0.9998 ± 0.0001\n",
      "\n",
      "---- Gradient Boosting ----\n",
      "Accuracy: 0.9984\n",
      "F1: 0.9984\n",
      "Precision: 0.9984\n",
      "Recall: 0.9984\n",
      "ROC AUC: 0.9998\n",
      "\n",
      "Cross-validation Results:\n",
      "accuracy: 0.9977 ± 0.0004\n",
      "f1: 0.9977 ± 0.0004\n",
      "precision: 0.9977 ± 0.0004\n",
      "recall: 0.9977 ± 0.0004\n",
      "roc_auc: 0.9999 ± 0.0001\n",
      "\n",
      "---- XGBoost ----\n",
      "Accuracy: 0.9991\n",
      "F1: 0.9991\n",
      "Precision: 0.9991\n",
      "Recall: 0.9991\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "Cross-validation Results:\n",
      "accuracy: 0.9986 ± 0.0003\n",
      "f1: 0.9986 ± 0.0003\n",
      "precision: 0.9986 ± 0.0003\n",
      "recall: 0.9986 ± 0.0003\n",
      "roc_auc: 1.0000 ± 0.0000\n",
      "\n",
      "---- Naïve Bayes ----\n",
      "Accuracy: 0.6962\n",
      "F1: 0.6674\n",
      "Precision: 0.8028\n",
      "Recall: 0.6962\n",
      "ROC AUC: 0.9592\n",
      "\n",
      "Cross-validation Results:\n",
      "accuracy: 0.6946 ± 0.0055\n",
      "f1: 0.6646 ± 0.0068\n",
      "precision: 0.8056 ± 0.0047\n",
      "recall: 0.6946 ± 0.0055\n",
      "roc_auc: 0.9618 ± 0.0050\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score, recall_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report,\n",
    "                             make_scorer)\n",
    "from sklearn.model_selection import cross_validate\n",
    "import joblib\n",
    "\n",
    "# Improved cross-validation setup\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Enhanced models configuration with proper naming for pipeline steps\n",
    "models = {\n",
    "    \"Logistic Regression\": make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(C=0.01, penalty='l2', random_state=42, max_iter=1000)\n",
    "    ),\n",
    "    \"SVM\": make_pipeline(\n",
    "        StandardScaler(),\n",
    "        SVC(C=0.1, kernel='linear', random_state=42, probability=True)\n",
    "    ),\n",
    "    \"KNN\": make_pipeline(\n",
    "        StandardScaler(),\n",
    "        KNeighborsClassifier(n_neighbors=10, weights='uniform')\n",
    "    ),\n",
    "    \"Random Forest\": RandomForestClassifier(\n",
    "        n_estimators=150, max_depth=5, min_samples_split=10,\n",
    "        max_features=0.5, random_state=42, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "        n_estimators=150, learning_rate=0.05, max_depth=3,\n",
    "        subsample=0.8, random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=150, learning_rate=0.05, max_depth=6,\n",
    "        reg_lambda=1.0, reg_alpha=0.5, gamma=0.1,\n",
    "        random_state=42, n_jobs=-1, eval_metric='logloss',\n",
    "        scale_pos_weight=1),  # Adjust if class imbalance exists\n",
    "    \"Naïve Bayes\": GaussianNB(var_smoothing=1e-9)\n",
    "}\n",
    "\n",
    "# Define scoring metrics\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1': 'f1_weighted',\n",
    "    'precision': 'precision_weighted',\n",
    "    'recall': 'recall_weighted',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "# Enhanced evaluation function\n",
    "def evaluate_model(name, model, X_train, X_test, y_train, y_test, cv):\n",
    "    print(f\"\\n---- {name} ----\")\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "    \n",
    "    # Performance metrics\n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred, average='weighted'),\n",
    "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
    "        'Recall': recall_score(y_test, y_pred, average='weighted')\n",
    "    }\n",
    "    \n",
    "    if y_proba is not None:\n",
    "        metrics['ROC AUC'] = roc_auc_score(y_test, y_proba)\n",
    "    \n",
    "    # Print metrics\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Cross-validation with multiple metrics\n",
    "    cv_results = cross_validate(\n",
    "        model, X_train, y_train, cv=cv,\n",
    "        scoring=scoring, n_jobs=-1, error_score='raise'\n",
    "    )\n",
    "    \n",
    "    print(\"\\nCross-validation Results:\")\n",
    "    for metric in scoring.keys():\n",
    "        mean_score = np.mean(cv_results[f'test_{metric}'])\n",
    "        std_score = np.std(cv_results[f'test_{metric}'])\n",
    "        print(f\"{metric}: {mean_score:.4f} ± {std_score:.4f}\")\n",
    "\n",
    "    \n",
    "# Run evaluation for all models\n",
    "for name, model in models.items():\n",
    "    evaluate_model(\n",
    "        name=name,\n",
    "        model=model,\n",
    "        X_train=X_train,\n",
    "        X_test=X_test,\n",
    "        y_train=y_train,\n",
    "        y_test=y_test,\n",
    "        cv=skf\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to disk!\n"
     ]
    }
   ],
   "source": [
    "# Save the model and scaler\n",
    "import joblib\n",
    "\n",
    "# Save the models using loop \n",
    "for name, model in models.items():\n",
    "    joblib.dump(model, f'./models/{name}.pkl')\n",
    "\n",
    "print(\"Saved to disk!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
